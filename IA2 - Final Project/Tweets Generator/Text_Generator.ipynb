{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text_Generator.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c25e5aa00708488590d1c7c34dacab5c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_59cf1b3dfefe49ad89d99992afff8c98","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ee240466ebac4cd081b410e10ae1e4ab","IPY_MODEL_9cfabb70226c4d4e9c8a4575b39b65b7"]}},"59cf1b3dfefe49ad89d99992afff8c98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee240466ebac4cd081b410e10ae1e4ab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_608150cb56a242ef9260800073c61fb3","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":817,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":817,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1ff839e6920941c3a7c78543a99a4209"}},"9cfabb70226c4d4e9c8a4575b39b65b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7ead26bb9c24495386bf87d37c476d53","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 817/817 [00:03&lt;00:00, 264B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_15f36cbd93334396936e32ebbba91de8"}},"608150cb56a242ef9260800073c61fb3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1ff839e6920941c3a7c78543a99a4209":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ead26bb9c24495386bf87d37c476d53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"15f36cbd93334396936e32ebbba91de8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f2c8058e83aa4e3c90e4f09d62a5cc3b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_341e9cd597ed4c548f8c6ca61f0460b7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_32f423f0482140e7910f9ad873d08079","IPY_MODEL_0560a2bfead341db833e59411cee227b"]}},"341e9cd597ed4c548f8c6ca61f0460b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"32f423f0482140e7910f9ad873d08079":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8bb7384670c7480992c7764b753031da","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":849679,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":849679,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0241bee3cddc47a38b7500fc5778b9ff"}},"0560a2bfead341db833e59411cee227b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_00e91184fd644a16862ac5a335efebab","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 850k/850k [00:02&lt;00:00, 323kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f5cbc02ad48447c4ac5079ccfee6bd33"}},"8bb7384670c7480992c7764b753031da":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0241bee3cddc47a38b7500fc5778b9ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"00e91184fd644a16862ac5a335efebab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f5cbc02ad48447c4ac5079ccfee6bd33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d26f32c8bc97463f820b89f1b4a4793f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b9118acc2bfc4206ab47caf8650dfd48","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_17aa8d30b690411b820c253824089589","IPY_MODEL_fe8880670b8345f795a3a939ebf2e37a"]}},"b9118acc2bfc4206ab47caf8650dfd48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"17aa8d30b690411b820c253824089589":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_66efd5173fc04a8794f76bf9a56ce3e6","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":507987,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":507987,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e4da90408b9a4eaaa8c79202233561bc"}},"fe8880670b8345f795a3a939ebf2e37a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a4962107f9584b0c8735da06a41625e3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 508k/508k [00:01&lt;00:00, 438kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_19893d1c016a4588850339910013fcef"}},"66efd5173fc04a8794f76bf9a56ce3e6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e4da90408b9a4eaaa8c79202233561bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a4962107f9584b0c8735da06a41625e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"19893d1c016a4588850339910013fcef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5ee8c5396ef541ecaa717f2821d39510":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2b243babab3b41ec830dfc5e036a2e59","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6602af760e3f415094c2dafd8810ebd6","IPY_MODEL_97a054af097841bba065bc6dc989f514"]}},"2b243babab3b41ec830dfc5e036a2e59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6602af760e3f415094c2dafd8810ebd6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2219ce560f1b48b1b12e5fe47ba2f985","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":387,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":387,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_18865d09075c4c64a1cab44c9ad34bc8"}},"97a054af097841bba065bc6dc989f514":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_60c87993a25849bca9103525a621486c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 387/387 [00:00&lt;00:00, 689B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dd89fcf53a1c4f20a515b826ad4bab9f"}},"2219ce560f1b48b1b12e5fe47ba2f985":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"18865d09075c4c64a1cab44c9ad34bc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"60c87993a25849bca9103525a621486c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dd89fcf53a1c4f20a515b826ad4bab9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"69ce8d54c78947be8b5dfb132a1d15a3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_376849b4052f47469225a9942c7b8456","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5c081f2984104a5fba58cac5ab603a3c","IPY_MODEL_365de4f126c9483a93aeb2aeaf31ac0e"]}},"376849b4052f47469225a9942c7b8456":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5c081f2984104a5fba58cac5ab603a3c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a843dfdc47fc4940a9180428c4907966","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":620,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":620,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_950aa569444f44a8a5090b019b03bc49"}},"365de4f126c9483a93aeb2aeaf31ac0e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_baf217fce0e3415fb08abc7a5f83fd52","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 620/620 [00:00&lt;00:00, 6.22kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c0a03122b4d147b68f7adb638a1b6bd0"}},"a843dfdc47fc4940a9180428c4907966":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"950aa569444f44a8a5090b019b03bc49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"baf217fce0e3415fb08abc7a5f83fd52":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c0a03122b4d147b68f7adb638a1b6bd0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"52ee31c0949f4dd49078b36f27f0d6c1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cedd7ed8086a476f86e47e21fb30bd50","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d7e7cf10c276485d8d7768492a13d82a","IPY_MODEL_3e798a9d2c8c43ee80d1d429d46367a3"]}},"cedd7ed8086a476f86e47e21fb30bd50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d7e7cf10c276485d8d7768492a13d82a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_439047cb690540d589a67ce8f2c1bfbe","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":510408315,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":510408315,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f866d67c249c4e3f877003c9df7c31f3"}},"3e798a9d2c8c43ee80d1d429d46367a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a3825569364740d68f8bc8b6264710bc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 510M/510M [00:13&lt;00:00, 36.5MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5e602b4f0ed64e779f8198a170c5896a"}},"439047cb690540d589a67ce8f2c1bfbe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f866d67c249c4e3f877003c9df7c31f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a3825569364740d68f8bc8b6264710bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5e602b4f0ed64e779f8198a170c5896a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BP9Lg09GzS-4","executionInfo":{"status":"ok","timestamp":1615346649591,"user_tz":480,"elapsed":40149,"user":{"displayName":"Christian Ruiz","photoUrl":"https://lh5.googleusercontent.com/-jNIUgvhwfVo/AAAAAAAAAAI/AAAAAAAAVx4/adTiQZlOLI4/s64/photo.jpg","userId":"04549526520935802116"}},"outputId":"46e19f06-6ff4-4acb-ed4d-e7f22198684f"},"source":["#@title **MONTAR EL DRIVE** { display-mode: \"form\" }\r\n","import os\r\n","from google.colab import drive\r\n","drive.mount('/content/drive/')\r\n","os.chdir('/content/drive/My Drive/ia2_project/Tweets Generator')\r\n","print(os.getcwd())\r\n","print(os.listdir())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n","/content/drive/My Drive/ia2_project/Trabajo Christian\n","['cached_lm_GPT2TokenizerFast_128_train_dataset.txt', 'cached_lm_GPT2TokenizerFast_128_test_dataset.txt', 'gpt2-tuits', 'runs', 'gpt2-tuits+gobierno', 'gpt2-gobierno', 'gpt2-gobierno_5', 'gpt2-gobierno_10', 'gpt2-tuits+gobierno_40', 'gpt2-tuits+gobierno_50', 'test_dataset.txt', 'train_dataset.txt', 'cached_lm_GPT2TokenizerFast_128_train_dataset.txt.lock', 'cached_lm_GPT2TokenizerFast_128_test_dataset.txt.lock', 'Text_Generator.ipynb']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_ozSE5OnltnK"},"source":["# **Modelos de Generación de Texto - Estado del Arte**\r\n","\r\n","\r\n","---\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"PYQFjpp_uSa-"},"source":["Dentro de los modelos de generación de texto, quizás haya escuchado alguna vez del modelo de lenguaje GPT-2, o más recientemente GPT-3 de OpenAI. En donde estos modelos son capaces hasta de escribir código, como JSX, o HTML.\r\n","\r\n","Una desventaja del modelo GPT-3 son sus 175 mil millones de parámetros (175B), lo que da como resultado un tamaño de modelo de alrededor de 350 GB. A modo de comparación, el modelo más grande de GPT-2 tiene 1,5 mil millones de parámetros. Esto es, menos de 1/116 del tamaño de GPT-3.\r\n","\r\n","\r\n","De hecho, con cerca de 175B de parámetros entrenables, GPT-3 es mucho más grande en términos de tamaño en comparación con cualquier otro modelo que existe en la actualidad. A continuación se puede ver una comparación de la cantidad de parámetros de los modelos populares recientes de NLP, GPT-3 se destaca claramente."]},{"cell_type":"markdown","metadata":{"id":"KNmsGONulL0L"},"source":["<img src=\"https://miro.medium.com/max/2400/1*jBl-cX-CmFliPxR3AabBFA.png\" /></"]},{"cell_type":"markdown","metadata":{"id":"lchtCsS6uTCI"},"source":["Ahora bien, para entrenar un modelo de estas magnitudes, es necesario tanto de una cantidad de datos demasiado enorme, así como de un poder de computo abismal. \r\n","\r\n","Como dato curioso, entrenar GPT-3 tomaría alrededor de **355 años** en una Tesla V100, la GPU más rápida del mercado. Y costaría un estimado de $4,600,000 para ser entrenada con el proveedor de GPU más barato en la nube."]},{"cell_type":"markdown","metadata":{"id":"mPT41v2KSgFW"},"source":["<center><img src=\"https://images.contentstack.io/v3/assets/blt71da4c740e00faaa/blt5f77997b6858e850/60149e0f0069f70f7772189f/Approximate-size-comparison-of-GPT-2.jpg\" /></center>"]},{"cell_type":"markdown","metadata":{"id":"9qaW_0HaP-7P"},"source":["Por otra parte, para hacernos una idea de la cantidad de datos requerida para entrenar estos modelos, se conoce que, para entrenar el modelo GPT-2 de 1.5B de parametros, se utilizó un dataset de 8 millones de páginas web. Por todo esto, y debido a que para efectos de la realización de nuestro proyecto, sería imposible entrenar modelos de estas magnitudes; incursionaremos en el modelo GPT-2, el cual cuenta con modelos más pequeños (con menos parámetros) pero que hacen posible llevar a cabo un proceso de fine-tune."]},{"cell_type":"markdown","metadata":{"id":"Gp1LGTuYVT5J"},"source":["## **Modelos GPT-2 - Número de Parámetros**\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"tw0Dm4A0w_YT"},"source":["<img src=\"https://jalammar.github.io/images/gpt2/gpt2-sizes.png\" />"]},{"cell_type":"markdown","metadata":{"id":"qeSUt5wcWMGa"},"source":["Debido a que estos modelos han sido entrenados en Inglés, nuestra tarea de implementar un modelo de generación de texto en Español adquiere mayor dificultad. Pensar en re-entrenar el modelo desde cero sería una tarea demasiado costosa en términos de información, poder computacional y dinero. Por lo cual, es más realista conseguir información o datasets menos robustos y hacer fine-tune a un modelo pre-entrenado en Inglés.\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","---\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"vVDoG625afPu"},"source":["### **¿Qué es hacer Fine-Tune?**"]},{"cell_type":"markdown","metadata":{"id":"2GdEanGxb2WL"},"source":["Fine-tune significa tomar pesos de una red neuronal ya entrenada y usarla como inicialización para un nuevo modelo que se va a entrenar con datos del mismo dominio. Es decir, para nuestro caso particular, la re-utilización del vocabulario y las matrices de embeddings (todos los vectores de tokens **en común** entre Inglés y Español se mantienen), así como los pesos del modelo aprendidos en un corpus en Inglés (40gb de texto).\r\n","\r\n","Esta estrategia es factible porque las reglas gramáticales entre el Inglés y Español, pese a ser diferentes, guardan algo de similitud.\r\n","\r\n","\r\n","\r\n","---\r\n","\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"Dxhx867wgnh7"},"source":["## **Arquitectura GPT-2**"]},{"cell_type":"markdown","metadata":{"id":"0oiyVjebuMqo"},"source":["\r\n","El modelo GPT-2 es un modelo emblemático de la revolución de los transformers en NLP desde 2017. Se ha caracterizado por ser capaz de escribir textos de una calidad cercana al nivel de los humanos. Pese a que actualmente ha sido superado en cuestión de parámetros y desempeño por modelos como BART, T5 y GPT-3, sigue siendo una referencia y objeto de estudio e investigación en la actualidad.\r\n","\r\n","Este modelo se basa en la parte **decoder** de la arquitectura Transformer."]},{"cell_type":"markdown","metadata":{"id":"BVEUScMGocSB"},"source":["## **¿Cómo funcionan los Transformers?**"]},{"cell_type":"markdown","metadata":{"id":"dPeurX0Qq-Du"},"source":["El modelo de transformers original está compuesto por un encoder y un decoder; cada uno es un stack (pila) de lo que podemos llamar bloques de transformers. Esta arquitectura era apropiada para tareas como la traducción automática, un problema en el que las arquitecturas encoder-decoder han tenido éxito en el pasado."]},{"cell_type":"markdown","metadata":{"id":"Elsi7k4sophY"},"source":["<center><img src=\"http://jalammar.github.io/images/t/The_transformer_encoder_decoder_stack.png\" /></center>"]},{"cell_type":"markdown","metadata":{"id":"Rp2EtBb4sAIE"},"source":["Gran parte del trabajo de investigación posterior vio a la arquitectura deshacerse o bien del encoder o decoder, y usar solo un stack de bloques de transformers, apilándo tantos como fuese posible y alimentándolos con cantidades masivas de texto de entrenamiento y un enorme poder de computo, sin dejar de lado la basta inversión monetaria."]},{"cell_type":"markdown","metadata":{"id":"U-3ocAN6s37S"},"source":["<center><img src=\"http://jalammar.github.io/images/gpt2/gpt-2-transformer-xl-bert-3.png\" /></center>"]},{"cell_type":"markdown","metadata":{"id":"xzh1TNrVpKwm"},"source":["El modelo GPT-2 es construido usando bloques de decoders. Al igual que los modelos de lenguaje tradicionales, genera un token a la vez."]},{"cell_type":"markdown","metadata":{"id":"PEwxb_znoY8C"},"source":["<center><img src=\"https://miro.medium.com/max/700/1*C2pZ2jmq3XDNyzpHt6pSWQ.png\" /></center>"]},{"cell_type":"markdown","metadata":{"id":"TxtKY9DRpeBp"},"source":["La forma en que estos modelos realmente funcionan es que después de que se produce cada token, ese token se agrega a la secuencia de entradas. Esa nueva secuencia se convierte en la entrada al modelo en su siguiente paso. Esta idea es llamada \"autoregresión\" y es una de las ideas que hizo que las RNN fueran tan efectivas."]},{"cell_type":"markdown","metadata":{"id":"6bGNjgo7E3IP"},"source":["## **El Decoder-Only Block**"]},{"cell_type":"markdown","metadata":{"id":"FsOz0B1pYZdj"},"source":["El modelo GPT-2 de OpenAI usa estos decoder-only blocks.\r\n"]},{"cell_type":"markdown","metadata":{"id":"eQ6_lwvnrRBI"},"source":["<center><img src=\"https://miro.medium.com/max/700/1*Z-P4_8w9wVhIfgYz32NSoQ.png\" /></center>"]},{"cell_type":"markdown","metadata":{"id":"gUppSpmgUeuU"},"source":["Es importante que la distinción entre self-attention (usado por modelos como BERT) y masked self-attention (la que usa GPT-2) sea clara. Un bloque con una capa self-attention permite a las entradas intectactuar consigo mismas para aprender dependencias entre ellas y usar esa información para capturar la estructura interna de una frase. Por otra parte, la masked self-attention bloquea la información de los tokens que están a la derecha de la posición que está siendo calculada."]},{"cell_type":"markdown","metadata":{"id":"c5HTVFvquOuW"},"source":["<center><img src=\"http://jalammar.github.io/images/gpt2/self-attention-and-masked-self-attention.png\" /></center>"]},{"cell_type":"markdown","metadata":{"id":"f9CuOYjbe6Pe"},"source":["### **Descripción breve del modelo a utilizar:**\r\n","\r\n","**English pre-trained GPT-2 small**\r\n","*  12 capas, 768-ocultas\r\n","*  124M de parámetros\r\n","*  Tiempo de descarga: aproximadamente 10 minutos\r\n","\r\n","\r\n","**English pre-trained Byte-level BPE tokenizer**\r\n","*  Byte-level BPE\r\n","*  vocabulario de 50.257 tokens"]},{"cell_type":"markdown","metadata":{"id":"7MWCmDMvgaCF"},"source":["## **¿Qué es un tokenizer?**"]},{"cell_type":"markdown","metadata":{"id":"rKnWXFm3hyVq"},"source":["Tokenizar consiste esencialmente en dividir una frase, oración, párrafo o un documento de texto en unidades más pequeñas, como palabras o términos individuales (caracteres). Cada una de estas unidades más pequeñas se llama token.\r\n","\r\n","Para conocer más sobre el **BPE tokenizer**, véase: https://huggingface.co/transformers/master/tokenizer_summary.html"]},{"cell_type":"markdown","metadata":{"id":"HJwCdI7ohYri"},"source":["# **HUGGING FACE - Librería Transformers**\r\n","\r\n","\r\n","\r\n","---\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"weBZ3mvog6GL"},"source":["<center><img src=\"https://raw.githubusercontent.com/huggingface/transformers/master/docs/source/imgs/transformers_logo_name.png\" /></center>"]},{"cell_type":"markdown","metadata":{"id":"rRjsGAv9hVHq"},"source":["La librería **Transformers** provee el estado del arte en arquitecturas de Machine Learning como BERT, **GPT-2**, RoBERTa, XLM, DistilBert, XLNet, T5, para Natural Language Understanding (NLU), y Natural Language Generation (NLG). Provee cientos de modelos pre-entrenados en más de 100 idiomas diferentes siendo profundamente interoperables entre PyTorch y TensorFlow 2.0. Además, permite a los desarrolladores hacer **fine-tune** a dichos modelos para diferentes tareas de **NLP** como clasificación de texto, análisis de sentimientos o generación de texto."]},{"cell_type":"markdown","metadata":{"id":"uhQne8pfmhp6"},"source":["# **Implementación**"]},{"cell_type":"markdown","metadata":{"id":"nDIc3dukmlLJ"},"source":["Para la implementación, haremos **fine-tune** a la Spanish GPT-2 de los modelos pre-entrenados de Huggingface (esta implementación es a su vez producto de un proceso de fine-tune de la GPT-2 small original en Inglés). Respecto a los datos, usamos **web scrapping** para obtener tweets relacionados con la vacuna del covid-19 con un enfoque Hispanohablante (énfasis en Colombia). Llegamos a juntar alrededor de 17120 tweets.\r\n","\r\n","Usaremos estos tweets para hacer fine-tune a nuestro modelo GPT-2 que nos permita generar tweets que, en principio, hablen positiviamente o fomenten el uso de la vacuna.\r\n","\r\n","Implementación en Español de la GPT-2 Small: https://huggingface.co/datificate/gpt2-small-spanish "]},{"cell_type":"markdown","metadata":{"id":"hrAPO24Io0W3"},"source":["### **Pasos para llevar a cabo la implementacón:**\r\n","\r\n","* Cargar el dataset (datos recopilados por nosotros a través de **web scrapping**).\r\n","* Preparar el dataset y construir un **TextDataset**.\r\n","* Inicializar el **Trainer** con sus **TrainingArguments** y el modelo **GPT-2**.\r\n","* Entrenar y guardar el modelo.\r\n","* Testear el modelo.\r\n","\r\n","\r\n","\r\n","\r\n","---\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"95Bc8Uurz0ww","cellView":"form"},"source":["#@title **Importación de Librerias**\n","import tweepy as tw\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sXNyIuzn7hfy","executionInfo":{"status":"ok","timestamp":1615346707265,"user_tz":480,"elapsed":7688,"user":{"displayName":"Christian Ruiz","photoUrl":"https://lh5.googleusercontent.com/-jNIUgvhwfVo/AAAAAAAAAAI/AAAAAAAAVx4/adTiQZlOLI4/s64/photo.jpg","userId":"04549526520935802116"}},"outputId":"a36b6b78-a763-4b65-8813-967f2fe233e5"},"source":["!pip install transformers==4.2.2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers==4.2.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n","\r\u001b[K     |▏                               | 10kB 23.6MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 17.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 14.5MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 11.9MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 8.5MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61kB 8.9MB/s eta 0:00:01\r\u001b[K     |█▎                              | 71kB 10.0MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81kB 10.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 92kB 9.6MB/s eta 0:00:01\r\u001b[K     |█▉                              | 102kB 8.2MB/s eta 0:00:01\r\u001b[K     |██                              | 112kB 8.2MB/s eta 0:00:01\r\u001b[K     |██▎                             | 122kB 8.2MB/s eta 0:00:01\r\u001b[K     |██▍                             | 133kB 8.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 143kB 8.2MB/s eta 0:00:01\r\u001b[K     |██▉                             | 153kB 8.2MB/s eta 0:00:01\r\u001b[K     |███                             | 163kB 8.2MB/s eta 0:00:01\r\u001b[K     |███▏                            | 174kB 8.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 184kB 8.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 194kB 8.2MB/s eta 0:00:01\r\u001b[K     |███▊                            | 204kB 8.2MB/s eta 0:00:01\r\u001b[K     |████                            | 215kB 8.2MB/s eta 0:00:01\r\u001b[K     |████                            | 225kB 8.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 235kB 8.2MB/s eta 0:00:01\r\u001b[K     |████▌                           | 245kB 8.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 256kB 8.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 266kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 276kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 286kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 296kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 307kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 317kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 327kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 337kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 348kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 358kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 368kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 378kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 389kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 399kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 409kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 419kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 430kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 440kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 450kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 460kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 471kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 481kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 491kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 501kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 512kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 522kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 532kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 542kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 552kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 563kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 573kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 583kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 593kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 604kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 614kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 624kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 634kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 645kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 655kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 665kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 675kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 686kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 696kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 706kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 716kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 727kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 737kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 747kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 757kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 768kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 778kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 788kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 798kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 808kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 819kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 829kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 839kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 849kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 860kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 870kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 880kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 890kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 901kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 911kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 921kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 931kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 942kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 952kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 962kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 972kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 983kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 993kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.0MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.0MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.0MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.0MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.0MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.2MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.2MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.2MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.2MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.2MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.2MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.2MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.2MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.3MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.3MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.3MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.3MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.3MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.3MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.3MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.4MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.4MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.4MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.4MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.4MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.4MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.4MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.4MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.4MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.5MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.5MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.5MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.5MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.5MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.5MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.5MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.5MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.5MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.6MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.6MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.6MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.6MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.6MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.6MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.6MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.6MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.6MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.6MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.7MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.7MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.7MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.7MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.7MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.7MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.7MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.7MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.7MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.8MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8MB 8.2MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (20.9)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/36/59e4a62254c5fcb43894c6b0e9403ec6f4238cc2422a003ed2e6279a1784/tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 45.4MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (3.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (1.19.5)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 52.6MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.2) (3.0.12)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.2.2) (2.4.7)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.2.2) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.2.2) (3.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.2) (1.0.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.2) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.2) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.2) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.2) (2020.12.5)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=6060451a19deb7b89ceae738907603db7a3d6fd605e97f77f5844e33d7702cdb\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dzPelxCA88Qe","executionInfo":{"status":"ok","timestamp":1615239956494,"user_tz":300,"elapsed":866,"user":{"displayName":"Christian Ruiz","photoUrl":"https://lh5.googleusercontent.com/-jNIUgvhwfVo/AAAAAAAAAAI/AAAAAAAAVx4/adTiQZlOLI4/s64/photo.jpg","userId":"04549526520935802116"}},"outputId":"3cdefa9a-2eac-4b07-9b51-33798e43df96"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon Mar  8 21:45:55 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hzP_-Rus_bQF"},"source":["# **Lectura y Procesamiento del Dataset**"]},{"cell_type":"markdown","metadata":{"id":"9egTWiADzB12"},"source":["Para la recolección de los datos, como se mencionó anteriormente, se realizó un proceso de web scrapping, del cual se extrajeron alrededor de 17000 tweets los cuales se cargan a continuación:"]},{"cell_type":"code","metadata":{"id":"eXGpFV7Yz4Pf"},"source":["data1 = pd.read_csv('../data/data_generator/tweets_covid_2241-2020-012-021.csv')\r\n","data2 = pd.read_csv('../data/data_generator/tweets_covid_5236-2021-03-04.csv')\r\n","data3 = pd.read_csv('../data/data_generator/tweets_covid_1083-2020-09-017.csv')\r\n","data4 = pd.read_csv('../data/data_classifier/tweets/tweets_covid_positivo5054.csv')\r\n","data5 = pd.read_csv('../data/data_generator/tweets_gobierno_clean.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TMiBdDYv0RP-"},"source":["tweets = pd.concat([data1, data2, data3, data4, data5])\r\n","tweets.reset_index(drop=True, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jb5V_SeY0tvu","executionInfo":{"status":"ok","timestamp":1615239962942,"user_tz":300,"elapsed":4518,"user":{"displayName":"Christian Ruiz","photoUrl":"https://lh5.googleusercontent.com/-jNIUgvhwfVo/AAAAAAAAAAI/AAAAAAAAVx4/adTiQZlOLI4/s64/photo.jpg","userId":"04549526520935802116"}},"outputId":"f8b5c3ea-c1ee-41ec-d951-e495409b618b"},"source":["tweets"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Nombre de usuario</th>\n","      <th>Usuario</th>\n","      <th>Fecha</th>\n","      <th>Texto</th>\n","      <th>Unnamed: 0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Carlos Arturo Ospina Vanegas</td>\n","      <td>@CarlosA99231303</td>\n","      <td>2020-12-21T23:54:40.000Z</td>\n","      <td>Si nosotros compramos la vacuna directamente n...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Anvi</td>\n","      <td>@IvannRodriguezn</td>\n","      <td>2020-12-21T23:50:42.000Z</td>\n","      <td>Colombia no puede negarle la vacuna a Venezola...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Carlos Daniel Galvis</td>\n","      <td>@carlosdgalvis</td>\n","      <td>2020-12-21T23:42:45.000Z</td>\n","      <td>Después de escuchar al señor Presidente de la ...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Francesco Manetto</td>\n","      <td>@fmanetto</td>\n","      <td>2020-12-21T23:29:04.000Z</td>\n","      <td>Decenas, probablemente cientos de miles de per...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Isabel III</td>\n","      <td>@IssaCgv</td>\n","      <td>2020-12-21T23:26:22.000Z</td>\n","      <td>Acabo de ver lo de Colombia con la exclusión d...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>17115</th>\n","      <td>SecretaríaSaludCesar</td>\n","      <td>@CesarSecSalud</td>\n","      <td>2020-03-09</td>\n","      <td>Hoy, @CesarSecSalud en conjunto con @SecSaludV...</td>\n","      <td>981.0</td>\n","    </tr>\n","    <tr>\n","      <th>17116</th>\n","      <td>SecretaríaSaludCesar</td>\n","      <td>@CesarSecSalud</td>\n","      <td>2020-03-09</td>\n","      <td>Descarga CoronApp y despeja todas tus dudas so...</td>\n","      <td>982.0</td>\n","    </tr>\n","    <tr>\n","      <th>17117</th>\n","      <td>SecretaríaSaludCesar</td>\n","      <td>@CesarSecSalud</td>\n","      <td>2020-03-09</td>\n","      <td>En la mesa sobre#Coronavirus #COVID19 particip...</td>\n","      <td>980.0</td>\n","    </tr>\n","    <tr>\n","      <th>17118</th>\n","      <td>SecretaríaSaludCesar</td>\n","      <td>@CesarSecSalud</td>\n","      <td>2020-03-07</td>\n","      <td>Seguimos avanzando en acciones contra el #Deng...</td>\n","      <td>983.0</td>\n","    </tr>\n","    <tr>\n","      <th>17119</th>\n","      <td>Secretaría de Desarrollo de la Salud - Córdoba.</td>\n","      <td>@CordobaSalud</td>\n","      <td>2020-03-04</td>\n","      <td>A esta hora,  el secretarios de salud de Córdo...</td>\n","      <td>984.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>17120 rows × 5 columns</p>\n","</div>"],"text/plain":["                                     Nombre de usuario  ... Unnamed: 0\n","0                         Carlos Arturo Ospina Vanegas  ...        NaN\n","1                                                 Anvi  ...        NaN\n","2                                 Carlos Daniel Galvis  ...        NaN\n","3                                    Francesco Manetto  ...        NaN\n","4                                           Isabel III  ...        NaN\n","...                                                ...  ...        ...\n","17115                             SecretaríaSaludCesar  ...      981.0\n","17116                             SecretaríaSaludCesar  ...      982.0\n","17117                             SecretaríaSaludCesar  ...      980.0\n","17118                             SecretaríaSaludCesar  ...      983.0\n","17119  Secretaría de Desarrollo de la Salud - Córdoba.  ...      984.0\n","\n","[17120 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"XdLx3PjK04Lt"},"source":["tweets.dropna(inplace=True)\r\n","tweets.drop_duplicates(inplace=True)\r\n","tweets.reset_index(drop=True, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MBwHNMEM1POW","executionInfo":{"status":"ok","timestamp":1615239963223,"user_tz":300,"elapsed":4789,"user":{"displayName":"Christian Ruiz","photoUrl":"https://lh5.googleusercontent.com/-jNIUgvhwfVo/AAAAAAAAAAI/AAAAAAAAVx4/adTiQZlOLI4/s64/photo.jpg","userId":"04549526520935802116"}},"outputId":"0a0e62f3-9b0b-4a6f-fbc6-42aa9329210e"},"source":["tweets"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Nombre de usuario</th>\n","      <th>Usuario</th>\n","      <th>Fecha</th>\n","      <th>Texto</th>\n","      <th>Unnamed: 0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Carlos Arturo Ospina Vanegas</td>\n","      <td>@CarlosA99231303</td>\n","      <td>2020-12-21T23:54:40.000Z</td>\n","      <td>Si nosotros compramos la vacuna directamente n...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Anvi</td>\n","      <td>@IvannRodriguezn</td>\n","      <td>2020-12-21T23:50:42.000Z</td>\n","      <td>Colombia no puede negarle la vacuna a Venezola...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Carlos Daniel Galvis</td>\n","      <td>@carlosdgalvis</td>\n","      <td>2020-12-21T23:42:45.000Z</td>\n","      <td>Después de escuchar al señor Presidente de la ...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Francesco Manetto</td>\n","      <td>@fmanetto</td>\n","      <td>2020-12-21T23:29:04.000Z</td>\n","      <td>Decenas, probablemente cientos de miles de per...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Isabel III</td>\n","      <td>@IssaCgv</td>\n","      <td>2020-12-21T23:26:22.000Z</td>\n","      <td>Acabo de ver lo de Colombia con la exclusión d...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>17115</th>\n","      <td>SecretaríaSaludCesar</td>\n","      <td>@CesarSecSalud</td>\n","      <td>2020-03-09</td>\n","      <td>Hoy, @CesarSecSalud en conjunto con @SecSaludV...</td>\n","      <td>981.0</td>\n","    </tr>\n","    <tr>\n","      <th>17116</th>\n","      <td>SecretaríaSaludCesar</td>\n","      <td>@CesarSecSalud</td>\n","      <td>2020-03-09</td>\n","      <td>Descarga CoronApp y despeja todas tus dudas so...</td>\n","      <td>982.0</td>\n","    </tr>\n","    <tr>\n","      <th>17117</th>\n","      <td>SecretaríaSaludCesar</td>\n","      <td>@CesarSecSalud</td>\n","      <td>2020-03-09</td>\n","      <td>En la mesa sobre#Coronavirus #COVID19 particip...</td>\n","      <td>980.0</td>\n","    </tr>\n","    <tr>\n","      <th>17118</th>\n","      <td>SecretaríaSaludCesar</td>\n","      <td>@CesarSecSalud</td>\n","      <td>2020-03-07</td>\n","      <td>Seguimos avanzando en acciones contra el #Deng...</td>\n","      <td>983.0</td>\n","    </tr>\n","    <tr>\n","      <th>17119</th>\n","      <td>Secretaría de Desarrollo de la Salud - Córdoba.</td>\n","      <td>@CordobaSalud</td>\n","      <td>2020-03-04</td>\n","      <td>A esta hora,  el secretarios de salud de Córdo...</td>\n","      <td>984.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>17120 rows × 5 columns</p>\n","</div>"],"text/plain":["                                     Nombre de usuario  ... Unnamed: 0\n","0                         Carlos Arturo Ospina Vanegas  ...        NaN\n","1                                                 Anvi  ...        NaN\n","2                                 Carlos Daniel Galvis  ...        NaN\n","3                                    Francesco Manetto  ...        NaN\n","4                                           Isabel III  ...        NaN\n","...                                                ...  ...        ...\n","17115                             SecretaríaSaludCesar  ...      981.0\n","17116                             SecretaríaSaludCesar  ...      982.0\n","17117                             SecretaríaSaludCesar  ...      980.0\n","17118                             SecretaríaSaludCesar  ...      983.0\n","17119  Secretaría de Desarrollo de la Salud - Córdoba.  ...      984.0\n","\n","[17120 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"Tl-afDKA2RqA"},"source":["# **Creación de un dataset de texto**"]},{"cell_type":"markdown","metadata":{"id":"zv0WKLoiw-sl"},"source":["El siguiente paso es extraer el campo 'texto' de todos los tweets y construir un **TextDataset**. El **TextDataset** es una implementación personalizada de la clase **Dataset** de Pytorch implementada por la biblioteca de transformers. Este objeto TextDataset, como todo en HuggingFace, facilita el proceso de creación de un dataset apto para entrenar y testear nuestro modelo.\r\n","\r\n","La información para train y test se guardará en 'train_dataset.txt' y 'test_dataset.txt' respectivamente.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sHiLuxlg2DOg","executionInfo":{"status":"ok","timestamp":1615239967302,"user_tz":300,"elapsed":1995,"user":{"displayName":"Christian Ruiz","photoUrl":"https://lh5.googleusercontent.com/-jNIUgvhwfVo/AAAAAAAAAAI/AAAAAAAAVx4/adTiQZlOLI4/s64/photo.jpg","userId":"04549526520935802116"}},"outputId":"a0274fd0-448c-460a-cff4-fd9f5a8d042e"},"source":["import re\r\n","import json\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","\r\n","# with open('recipes.json') as f:\r\n","#     data = json.load(f)\r\n","\r\n","def build_text_files(df, dest_path):\r\n","    f = open(dest_path, 'w')\r\n","    data = ''\r\n","    summaries = df['Texto'].tolist()\r\n","    for texts in summaries:\r\n","        summary = str(texts).strip()\r\n","        summary = re.sub(r\"\\s\", \" \", summary)\r\n","        data += summary + \" \"\r\n","    f.write(data)\r\n","\r\n","train, test = train_test_split(tweets, test_size=0.15) \r\n","\r\n","\r\n","build_text_files(train,'train_dataset.txt')\r\n","build_text_files(test,'test_dataset.txt')\r\n","\r\n","print(\"Train dataset length: \"+str(len(train)))\r\n","print(\"Test dataset length: \"+ str(len(test)))\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train dataset length: 14552\n","Test dataset length: 2568\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2K0EVp68LSzd"},"source":["# **Cargar Tokenizers**"]},{"cell_type":"markdown","metadata":{"id":"QYCDMoLEvzzX"},"source":["El siguiente paso es descargar el tokenizer. Usaremos el tokenizer del modelo en Español gpt-2 alojado en Huggingface."]},{"cell_type":"code","metadata":{"id":"V1mJnIk19TzT","colab":{"base_uri":"https://localhost:8080/","height":262,"referenced_widgets":["c25e5aa00708488590d1c7c34dacab5c","59cf1b3dfefe49ad89d99992afff8c98","ee240466ebac4cd081b410e10ae1e4ab","9cfabb70226c4d4e9c8a4575b39b65b7","608150cb56a242ef9260800073c61fb3","1ff839e6920941c3a7c78543a99a4209","7ead26bb9c24495386bf87d37c476d53","15f36cbd93334396936e32ebbba91de8","f2c8058e83aa4e3c90e4f09d62a5cc3b","341e9cd597ed4c548f8c6ca61f0460b7","32f423f0482140e7910f9ad873d08079","0560a2bfead341db833e59411cee227b","8bb7384670c7480992c7764b753031da","0241bee3cddc47a38b7500fc5778b9ff","00e91184fd644a16862ac5a335efebab","f5cbc02ad48447c4ac5079ccfee6bd33","d26f32c8bc97463f820b89f1b4a4793f","b9118acc2bfc4206ab47caf8650dfd48","17aa8d30b690411b820c253824089589","fe8880670b8345f795a3a939ebf2e37a","66efd5173fc04a8794f76bf9a56ce3e6","e4da90408b9a4eaaa8c79202233561bc","a4962107f9584b0c8735da06a41625e3","19893d1c016a4588850339910013fcef","5ee8c5396ef541ecaa717f2821d39510","2b243babab3b41ec830dfc5e036a2e59","6602af760e3f415094c2dafd8810ebd6","97a054af097841bba065bc6dc989f514","2219ce560f1b48b1b12e5fe47ba2f985","18865d09075c4c64a1cab44c9ad34bc8","60c87993a25849bca9103525a621486c","dd89fcf53a1c4f20a515b826ad4bab9f","69ce8d54c78947be8b5dfb132a1d15a3","376849b4052f47469225a9942c7b8456","5c081f2984104a5fba58cac5ab603a3c","365de4f126c9483a93aeb2aeaf31ac0e","a843dfdc47fc4940a9180428c4907966","950aa569444f44a8a5090b019b03bc49","baf217fce0e3415fb08abc7a5f83fd52","c0a03122b4d147b68f7adb638a1b6bd0"]},"executionInfo":{"status":"ok","timestamp":1615239976388,"user_tz":300,"elapsed":7702,"user":{"displayName":"Christian Ruiz","photoUrl":"https://lh5.googleusercontent.com/-jNIUgvhwfVo/AAAAAAAAAAI/AAAAAAAAVx4/adTiQZlOLI4/s64/photo.jpg","userId":"04549526520935802116"}},"outputId":"3cb537d4-a5b9-41e7-b7e0-f2e61ac29652"},"source":["from transformers import AutoTokenizer\r\n","\r\n","tokenizer = AutoTokenizer.from_pretrained(\"datificate/gpt2-small-spanish\")\r\n","\r\n","train_path = 'train_dataset.txt'\r\n","test_path = 'test_dataset.txt'"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c25e5aa00708488590d1c7c34dacab5c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=817.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f2c8058e83aa4e3c90e4f09d62a5cc3b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=849679.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d26f32c8bc97463f820b89f1b4a4793f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=507987.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ee8c5396ef541ecaa717f2821d39510","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=387.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69ce8d54c78947be8b5dfb132a1d15a3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=620.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EuCsjJJXy-Sq"},"source":["Ahora podemos construir nuestro TextDataset. Para ello, creamos una instancia de TextDataset a la cual le suministramos el tokenizer y las rutas a nuestros datasets. Además, creamos un data_collator, el cual se utiliza en el entrenamiento para formar un batch a partir de nuestro dataset.\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K-rr_8w19fLc","executionInfo":{"status":"ok","timestamp":1615239980247,"user_tz":300,"elapsed":2364,"user":{"displayName":"Christian Ruiz","photoUrl":"https://lh5.googleusercontent.com/-jNIUgvhwfVo/AAAAAAAAAAI/AAAAAAAAVx4/adTiQZlOLI4/s64/photo.jpg","userId":"04549526520935802116"}},"outputId":"64148a9d-4280-4dbf-e783-ceeded661d08"},"source":["from transformers import TextDataset,DataCollatorForLanguageModeling\r\n","\r\n","def load_dataset(train_path,test_path,tokenizer):\r\n","    train_dataset = TextDataset(\r\n","          tokenizer=tokenizer,\r\n","          file_path=train_path,\r\n","          block_size=128)\r\n","     \r\n","    test_dataset = TextDataset(\r\n","          tokenizer=tokenizer,\r\n","          file_path=test_path,\r\n","          block_size=128)   \r\n","    \r\n","    data_collator = DataCollatorForLanguageModeling(\r\n","        tokenizer=tokenizer, mlm=False,\r\n","    )\r\n","    return train_dataset,test_dataset,data_collator\r\n","\r\n","train_dataset,test_dataset,data_collator = load_dataset(train_path,test_path,tokenizer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:58: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_mlm.py\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"mreZDbUqMUR1"},"source":["# **Definir Parámetros de Entrenamiento**"]},{"cell_type":"markdown","metadata":{"id":"0bA9OVZ00UE2"},"source":["La clase **Trainer** proporciona una API para un entrenamiento con todas las funciones. Se utiliza en la mayoría de los scripts de ejemplo de Huggingface. Antes de que podamos crear una instancia de Trainer, necesitamos descargar el modelo GPT-2 y crear un objeto **TrainingArguments**. Los TrainingArguments se utilizan para definir los hiperparámetros que usamos en el proceso de entrenamiento, como learning_rate, número de époocas, train_batch_size, etc. \r\n","\r\n","A continuación se puede encontrar la documentación de TrainingArguments: https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":120,"referenced_widgets":["52ee31c0949f4dd49078b36f27f0d6c1","cedd7ed8086a476f86e47e21fb30bd50","d7e7cf10c276485d8d7768492a13d82a","3e798a9d2c8c43ee80d1d429d46367a3","439047cb690540d589a67ce8f2c1bfbe","f866d67c249c4e3f877003c9df7c31f3","a3825569364740d68f8bc8b6264710bc","5e602b4f0ed64e779f8198a170c5896a"]},"id":"52jm_qOe90Ji","executionInfo":{"status":"ok","timestamp":1615240008670,"user_tz":300,"elapsed":25961,"user":{"displayName":"Christian Ruiz","photoUrl":"https://lh5.googleusercontent.com/-jNIUgvhwfVo/AAAAAAAAAAI/AAAAAAAAVx4/adTiQZlOLI4/s64/photo.jpg","userId":"04549526520935802116"}},"outputId":"e518abc2-6a26-4baa-825e-b89f2b2503da"},"source":["from transformers import Trainer, TrainingArguments, AutoModelWithLMHead\r\n","\r\n","model = AutoModelWithLMHead.from_pretrained(\"datificate/gpt2-small-spanish\")\r\n","\r\n","\r\n","training_args = TrainingArguments(\r\n","    output_dir=\"./gpt2-tuits+gobierno_50\", #The output directory\r\n","    overwrite_output_dir=True, #overwrite the content of the output directory\r\n","    num_train_epochs=50, # number of training epochs\r\n","    per_device_train_batch_size=32, # batch size for training\r\n","    per_device_eval_batch_size=64,  # batch size for evaluation\r\n","    eval_steps = 400, # Number of update steps between two evaluations.\r\n","    save_steps=4500, # after # steps model is saved \r\n","    warmup_steps=500,# number of warmup steps for learning rate scheduler\r\n","    prediction_loss_only=True,\r\n","    )\r\n","\r\n","\r\n","trainer = Trainer(\r\n","    model=model,\r\n","    args=training_args,\r\n","    data_collator=data_collator,\r\n","    train_dataset=train_dataset,\r\n","    eval_dataset=test_dataset,\r\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:925: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52ee31c0949f4dd49078b36f27f0d6c1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=510408315.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wTExqc7s1cuM"},"source":["En este caso, he decidido entrenar con 50 épocas, un batch size de entrenamiento de 32, un batch size de evaluation de 64. El optimizador es el optimizador por defecto, en este caso el Adam, y de la misma manera, el learning rate se dejó por defecto, el cual es 5e-5."]},{"cell_type":"markdown","metadata":{"id":"zRLEU4lEIxzg"},"source":["# **Entrenar el modelo**"]},{"cell_type":"code","metadata":{"id":"gFGyW-p_-M6B","colab":{"base_uri":"https://localhost:8080/","height":759},"executionInfo":{"status":"ok","timestamp":1615247343702,"user_tz":480,"elapsed":2451180,"user":{"displayName":"Christian Ruiz","photoUrl":"https://lh5.googleusercontent.com/-jNIUgvhwfVo/AAAAAAAAAAI/AAAAAAAAVx4/adTiQZlOLI4/s64/photo.jpg","userId":"04549526520935802116"}},"outputId":"80c16d9a-9f1b-47f3-a374-85da74207e4c"},"source":["trainer.train()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='4001' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4001/6000 1:21:17 < 40:38, 0.82 it/s, Epoch 33.33/50]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>4.504900</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>3.710300</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>3.347000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>3.087100</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>2.880500</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>2.709600</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>2.566900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='6000' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6000/6000 2:02:09, Epoch 50/50]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>4.504900</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>3.710300</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>3.347000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>3.087100</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>2.880500</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>2.709600</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>2.566900</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>2.452000</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>2.364200</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>2.293400</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>2.246000</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>2.218200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=6000, training_loss=2.865012268066406, metrics={'train_runtime': 7330.4464, 'train_samples_per_second': 0.819, 'total_flos': 18296832953548800, 'epoch': 50.0})"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"sVJcm3nquMeq"},"source":["Podemos observar como el entrenamiento con un dataset bastante pequeño como el nuestro, para 50 épocas, tardó alrededor de 2 horas en completarse. Ahora, guardemos el modelo que acabamos de entrenar."]},{"cell_type":"code","metadata":{"id":"W8gPyCWH-gfA"},"source":["trainer.save_model()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qK-CE_x3_PYB"},"source":["# **Testear el modelo - Generar texto**"]},{"cell_type":"markdown","metadata":{"id":"DnDIwTCu0ac2"},"source":["Para probar el modelo, usaremos otra objeto destacado de la biblioteca de transformers llamad **pipeline**. Pipelines son objetos que ofrecen una API simple dedicada a varias tareas, tales como generación de texto, entre otras."]},{"cell_type":"code","metadata":{"id":"RKxn5AMp_Pj-"},"source":["from transformers import pipeline\r\n","\r\n","generador_tweets = pipeline('text-generation',model='./gpt2-gobierno', tokenizer='datificate/gpt2-small-spanish',config={'max_length':800})\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TADGj8KT3LZx"},"source":["Una vez instanciado el pipeline, podemos generar tweets introduciendo un texto semilla, tal que:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"xy4FbOGz_e-l","executionInfo":{"status":"ok","timestamp":1615347698231,"user_tz":480,"elapsed":3050,"user":{"displayName":"Christian Ruiz","photoUrl":"https://lh5.googleusercontent.com/-jNIUgvhwfVo/AAAAAAAAAAI/AAAAAAAAVx4/adTiQZlOLI4/s64/photo.jpg","userId":"04549526520935802116"}},"outputId":"96677c17-5cf0-4080-d2b8-2673444ae857"},"source":["generador_tweets('El covid')[0]['generated_text']"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'El covid-19   #COVID19   #vacunassalvadoras Colombia sin vacuna!! El país en la peor crisis del mundo, donde las muertes y la falta de insumos hacen de los líderes más esenciales. La solución'"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"JkB04fvm0eAn"},"source":["Como conclusión, podriamos decir que hemos hecho un proceso exitoso de fine-tune para la generación de tweets relacionados con la vacuna del covid19. Sin embargo, los resultados pueden no ser los mejores, lo cual es una consecuencia directa del tamaño insuficiente del dataset. Se podría intentar ajustar mejor los paramétros de entrenamiento o aumentar las épocas, aunque esto último, podría conducir a overfitting.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"pN4_1ZzoCMEi"},"source":["# **Implementación de un bot en Twitter** (sólo para usos educativos)"]},{"cell_type":"markdown","metadata":{"id":"26FFusXDq4sK"},"source":["<img src=\"https://i.ibb.co/qprpK8v/uisbotxd.png\" />"]},{"cell_type":"code","metadata":{"id":"2j_JTL0aGXJL"},"source":["access_key = '1366595402603126784-C0khbB5IuWkO65Z5YndOG48QTR8jVu'   \r\n","access_secret = 'qQNLpD7EZlqgwJXK6WT1hvxaPFUhitPO0Ei3nJn5RDUdX'\r\n","consumer_key = 'lJS4GDO5S8IQrkuelETTlAxpx'  \r\n","consumer_secret = 'f7uLovJsAmOV5UAXZ2JJABFRXcjKl3tpmsGBRfRbSGWWDWsY4k'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ld81XEXFDVkP","executionInfo":{"status":"ok","timestamp":1615347847066,"user_tz":480,"elapsed":472,"user":{"displayName":"Christian Ruiz","photoUrl":"https://lh5.googleusercontent.com/-jNIUgvhwfVo/AAAAAAAAAAI/AAAAAAAAVx4/adTiQZlOLI4/s64/photo.jpg","userId":"04549526520935802116"}},"outputId":"65922def-64ab-44de-c543-857f0dc6ba03"},"source":["#@title **Realizar autenticación con la API de Twitter**\n","import tweepy\n","\n","# Authenticate to Twitter\n","auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n","auth.set_access_token(access_key, access_secret)\n","\n","# Create API object\n","api = tweepy.API(auth, wait_on_rate_limit=True,\n","    wait_on_rate_limit_notify=True)\n","\n","try:\n","    api.verify_credentials()\n","    print(\"Authentication OK\")\n","except:\n","    print(\"Error during authentication\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Authentication OK\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_23fC7QBESJ0"},"source":["#@title **Función para publicar tweets**\n","import time\n","semillas = ['Me parece', 'En el día de hoy, ', 'El covid', 'La vacuna', 'En Colombia']\n","# Create tweets\n","def publicarTweets(num_tweets, int_t):\n","  for i in range(num_tweets):\n","    api.update_status(generador_tweets(semillas[i])[0]['generated_text'])\n","    time.sleep(int_t)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"rPSsw-VnUJN4","executionInfo":{"status":"error","timestamp":1615348172410,"user_tz":480,"elapsed":114354,"user":{"displayName":"Christian Ruiz","photoUrl":"https://lh5.googleusercontent.com/-jNIUgvhwfVo/AAAAAAAAAAI/AAAAAAAAVx4/adTiQZlOLI4/s64/photo.jpg","userId":"04549526520935802116"}},"outputId":"516ce830-d228-4122-e132-3a2948d30f6b"},"source":["numTweets = 5 # Número de tweets a publicar.\r\n","t = 60 # Número de segundos a esperar hasta publicar otro tweet.\r\n","publicarTweets(numTweets, t)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"],"name":"stderr"},{"output_type":"error","ename":"TweepError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTweepError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-8a7610c963b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnumTweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;31m# Número de tweets a publicar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m \u001b[0;31m# Número de segundos a esperar hasta publicar otro tweet.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpublicarTweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumTweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-29-c9b4379a5543>\u001b[0m in \u001b[0;36mpublicarTweets\u001b[0;34m(num_tweets, int_t)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpublicarTweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_tweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerador_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msemillas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'generated_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36mupdate_status\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m                            'card_uri'],\n\u001b[1;32m    217\u001b[0m             \u001b[0mrequire_auth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         )(*args, **kwargs)\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmedia_upload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tweepy/binder.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tweepy/binder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRateLimitError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_error_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;31m# Parse the response payload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTweepError\u001b[0m: [{'code': 326, 'message': 'To protect our users from spam and other malicious activity, this account is temporarily locked. Please log in to https://twitter.com to unlock your account.'}]"]}]}]}